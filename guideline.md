# 📘 모델 학습 시 고려사항 가이드 📘 

모델이 우수한 성능을 낸다고 하더라도, 그 이유를 분석가/사이언티스트가 이해하지 못한다면 결코 의미 있지 않습니다.

👉 **코드를 짜는 시간보다 고민하는 데 더 많은 시간을 할애하세요.**

👉 **결과에 휘둘리기보다, 본인의 논리를 세우고 검증하는 습관**을 들이세요. 예상과 다르다면 다시 학습해가면 됩니다.

> 모든 부분에 힘을 주실 필요는 없습니다. 핵심 포인트에 집중하세요.

---

## 1️⃣ 결측치 처리

- 결측치를 확인하고 적절한 방식으로 대체해야 합니다.
- 대체 방식: 평균, 중앙값, 최빈값, 혹은 도메인 지식 기반의 값.

> **실습**
>
> - 시각화를 통해 결측치 확인
> - 대체 방법과 그 이유를 논리적으로 설명하기
<br>


## 2️⃣ 데이터 인코딩

범주형 변수는 모델이 이해할 수 있는 숫자형으로 변환해야 합니다.

- **Label Encoding**: 순서가 있는 경우
- **One-Hot Encoding**: 순서가 없는 경우
- **Target Encoding**: 타겟 변수 평균/비율 기반



> **실습**
>
> - 어떤 컬럼에 어떤 인코딩 방법을 썼는지
> - 고려한 다른 방법과 선택하지 않은 이유
<br>

## 3️⃣ 데이터 스케일링

- 데이터 분포를 모델링에 적합하게 변환하기 위해 필요.
- 예: MinMaxScaler, StandardScaler, RobustScaler



> **실습**
>
> - 정규화 필요성 논의
> - 선택한 스케일링 방법과 이유 설명
<br>

## 4️⃣ 데이터 왜도 (Skewness)

- 비대칭 분포는 성능 저하를 유발
- 변환 방법: 로그 변환, Box-Cox 변환 등



> **실습**
>
> - 각 컬럼 분포 시각화
> - 왜도 수치 계산
> - 타이타닉 데이터셋 예시 → 어떤 컬럼이 왜도 처리 필요한지?
<br>

## 5️⃣ 이상치 (Outliers)

- 이상치는 모델에 부정적 영향을 줄 수 있음
- 처리 방법: 제거, 대체(중앙값 등)



> **실습**
>
> - 이상치 기준을 제시
> - 처리 여부와 이유 설명
<br>

## **6️⃣ 피처 선택 및 생성**

- **Feature Selection**: 불필요한 변수 제거 → 과적합 방지
- **Feature Engineering**: 새로운 변수 생성 (예: 곱셈/나눗셈으로 새로운 특징)



> **실습**
>
> - 새로 만든 피처가 있다면 설명하기
> - 다중공선성 여부 확인 & 처리 방법 제시 
<br>


## **7️⃣ 데이터 분할**

- 훈련/검증/테스트 데이터 분할
- 일반적으로 **70~80% → 훈련 / 나머지 → 검증·테스트**



> **실습**
>
> - K-Fold vs Stratified K-Fold 학습
> - 최종적으로 어떤 방법을 썼는지, 이유 설명
<br>


## 8️⃣ 모델 선택

- 데이터 특성에 맞는 모델 선정
  - 선형 관계 → 선형 회귀
  - 비선형 관계 → 트리 기반 모델 등



> **실습**
>
> - 예측하고자 하는 값의 유형에 따른 모델 선정 논리 제시
> - 대안 모델 추천 가능



- **하이퍼파라미터 튜닝**:

  Grid Search, Random Search 등으로 성능 최적화
<br>


## 9️⃣ 모델 평가

- 회귀: **MSE, MAE, R²**
- 분류: **Accuracy, Precision, Recall, F1-score**
- 교차 검증으로 일반화 성능 평가



> **실습**
>
> - 어떤 지표를 선택했는지와 그 이유 설명
<br>


## 🔟 과적합 방지

- **정규화**: L1, L2 규제로 복잡도 조절
- **Dropout**: 신경망에서 일부 노드 무작위 제거
- **Early Stopping**: 검증 성능이 개선되지 않으면 조기 종료



> **실습**
>
> - 과적합 방지를 위해 사용한 방법
> - 방법의 원리와 장점 설명



📌 **출처**: 4기 교육팀장님
